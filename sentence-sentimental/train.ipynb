{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/final/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import DebertaV2ForSequenceClassification\n",
    "\n",
    "from dataset.datasets import SentimentalDataset\n",
    "from metrics.metrics import compute_metrics\n",
    "\n",
    "from sklearn.datasets import load_iris # ìƒ˜í”Œ ë°ì´í„° ë¡œë”©\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.utils import config_seed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "config_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ëª¨ë¸ ë° í† í¬ë‚˜ì´ì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"team-lucid/deberta-v3-base-korean\"\n",
    "\n",
    "# model = DebertaV2ForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„°ì…‹ êµ¬ì„±"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) ê¸°ì‚¬ ì „ì²´ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/opt/ml/finance_sentiment_corpus/merged_samsung_filtered.csv')\n",
    "\n",
    "# def extract_label(json_str) :\n",
    "#     data_dict = eval(json_str)  # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "#     return data_dict[\"label\"]\n",
    "\n",
    "# # \"label\" ê°’ì„ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ Series ìƒì„±\n",
    "# data['labels'] = data[\"labels\"].apply(extract_label)\n",
    "# data['labels'] = data['labels'].map({'ë¶€ì •':0, 'ê¸ì •':1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) ê¸°ì‚¬ ì•ë’¤ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>content_corpus</th>\n",
       "      <th>content_len</th>\n",
       "      <th>content_corpus_len</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ...</td>\n",
       "      <td>2023.07.10 15:29</td>\n",
       "      <td>ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...</td>\n",
       "      <td>ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...</td>\n",
       "      <td>1813</td>\n",
       "      <td>1651</td>\n",
       "      <td>1</td>\n",
       "      <td>. ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ... ì±—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—°</td>\n",
       "      <td>2023.07.10 15:07</td>\n",
       "      <td>ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...</td>\n",
       "      <td>ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...</td>\n",
       "      <td>1749</td>\n",
       "      <td>1698</td>\n",
       "      <td>0</td>\n",
       "      <td>. â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—° ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰</td>\n",
       "      <td>2023.07.10 15:05</td>\n",
       "      <td>í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥[ì„œìš¸=ë‰´ì‹œìŠ¤] SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥. (...</td>\n",
       "      <td>í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥ SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥.  .   ìƒí™œìœ ë¦¬...</td>\n",
       "      <td>547</td>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>. SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰ í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ</td>\n",
       "      <td>2023.07.10 14:58</td>\n",
       "      <td>ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...</td>\n",
       "      <td>ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...</td>\n",
       "      <td>1096</td>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "      <td>. â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ ë¶ë¯¸Â·ìœ ëŸ½ ë“±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤</td>\n",
       "      <td>2023.07.10 14:48</td>\n",
       "      <td>29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...</td>\n",
       "      <td>29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...</td>\n",
       "      <td>1759</td>\n",
       "      <td>1659</td>\n",
       "      <td>1</td>\n",
       "      <td>. ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤ 29ë…„ê°„ 3ë§Œ6558í¸...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0             0             0           0   \n",
       "1             2             2             2           2   \n",
       "2             3             3             3           3   \n",
       "3             4             4             4           4   \n",
       "4             5             5             5           5   \n",
       "\n",
       "                                        title              date  \\\n",
       "0  ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ...  2023.07.10 15:29   \n",
       "1            â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—°  2023.07.10 15:07   \n",
       "2            SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰  2023.07.10 15:05   \n",
       "3        â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ  2023.07.10 14:58   \n",
       "4             ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤  2023.07.10 14:48   \n",
       "\n",
       "                                             content  \\\n",
       "0  ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...   \n",
       "1  ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...   \n",
       "2  í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥[ì„œìš¸=ë‰´ì‹œìŠ¤] SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥. (...   \n",
       "3  ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...   \n",
       "4  29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...   \n",
       "\n",
       "                                      content_corpus  content_len  \\\n",
       "0  ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...         1813   \n",
       "1  ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...         1749   \n",
       "2  í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥ SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥.  .   ìƒí™œìœ ë¦¬...          547   \n",
       "3  ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...         1096   \n",
       "4  29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...         1759   \n",
       "\n",
       "   content_corpus_len  labels  \\\n",
       "0                1651       1   \n",
       "1                1698       0   \n",
       "2                 476       1   \n",
       "3                1029       1   \n",
       "4                1659       1   \n",
       "\n",
       "                                          new_column  \n",
       "0  . ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ... ì±—...  \n",
       "1  . â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—° ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ...  \n",
       "2  . SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰ í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µ...  \n",
       "3  . â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ ë¶ë¯¸Â·ìœ ëŸ½ ë“±...  \n",
       "4  . ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤ 29ë…„ê°„ 3ë§Œ6558í¸...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/opt/ml/finance_sentiment_corpus/merged_samsung_filtered.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# titleê³¼ content_corpusì—ì„œ ì›í•˜ëŠ” ë¬¸ì¥ ì¶”ì¶œ\n",
    "def extract_sentences(text):\n",
    "    sentences = text.split('. ')\n",
    "    if len(sentences) >= 5 :\n",
    "        return '. '.join([sentences[0], sentences[1], sentences[-2], sentences[-1]])\n",
    "    else :\n",
    "        return '. '+text\n",
    "    \n",
    "def extract_label(json_str) :\n",
    "    data_dict = eval(json_str)  # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "    return data_dict[\"label\"]\n",
    "\n",
    "# \"label\" ê°’ì„ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ Series ìƒì„±\n",
    "data['labels'] = data[\"labels\"].apply(extract_label)\n",
    "data['new_column'] = data.apply(lambda row: extract_sentences(row['title']) + ' ' + extract_sentences(row['content_corpus']), axis=1)\n",
    "data['labels'] = data['labels'].map({'ë¶€ì •':0, 'ê¸ì •':1})\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.3</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>content_corpus</th>\n",
       "      <th>content_len</th>\n",
       "      <th>content_corpus_len</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ...</td>\n",
       "      <td>2023.07.10 15:29</td>\n",
       "      <td>ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...</td>\n",
       "      <td>ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...</td>\n",
       "      <td>1813</td>\n",
       "      <td>1651</td>\n",
       "      <td>1</td>\n",
       "      <td>. ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ... ì±—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—°</td>\n",
       "      <td>2023.07.10 15:07</td>\n",
       "      <td>ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...</td>\n",
       "      <td>ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...</td>\n",
       "      <td>1749</td>\n",
       "      <td>1698</td>\n",
       "      <td>0</td>\n",
       "      <td>. â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—° ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰</td>\n",
       "      <td>2023.07.10 15:05</td>\n",
       "      <td>í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥[ì„œìš¸=ë‰´ì‹œìŠ¤] SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥. (...</td>\n",
       "      <td>í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥ SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥.  .   ìƒí™œìœ ë¦¬...</td>\n",
       "      <td>547</td>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>. SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰ í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ</td>\n",
       "      <td>2023.07.10 14:58</td>\n",
       "      <td>ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...</td>\n",
       "      <td>ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...</td>\n",
       "      <td>1096</td>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "      <td>. â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ ë¶ë¯¸Â·ìœ ëŸ½ ë“±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤</td>\n",
       "      <td>2023.07.10 14:48</td>\n",
       "      <td>29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...</td>\n",
       "      <td>29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...</td>\n",
       "      <td>1759</td>\n",
       "      <td>1659</td>\n",
       "      <td>1</td>\n",
       "      <td>. ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤ 29ë…„ê°„ 3ë§Œ6558í¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1861</td>\n",
       "      <td>1428</td>\n",
       "      <td>1567</td>\n",
       "      <td>1567</td>\n",
       "      <td>\"ë°˜ë„ì²´Â·ë””ìŠ¤í”Œë ˆì´Â·AIÂ·ë°”ì´ì˜¤ì— íˆ¬ì ì—­ëŸ‰ ì§‘ì¤‘í•´ì•¼\" [ì‚¼ì„± 'ì‹ ê²½ì˜...</td>\n",
       "      <td>2023.06.06 19:20</td>\n",
       "      <td>ì „ë¬¸ê°€ê°€ ë³´ëŠ” ë‰´ì‚¼ì„± ì „ëµ ë¹„ë©”ëª¨ë¦¬ì— ìŠ¹ë¶€ìˆ˜ ë˜ì ¸ì•¼ ì´ì¬ìš© ë“±ê¸°ì„ì› ë³µê·€ ì‹œê¸‰ ì‚¬ë²•...</td>\n",
       "      <td>ì „ë¬¸ê°€ê°€ ë³´ëŠ” ë‰´ì‚¼ì„± ì „ëµ ë¹„ë©”ëª¨ë¦¬ì— ìŠ¹ë¶€ìˆ˜ ë˜ì ¸ì•¼ ì´ì¬ìš© ë“±ê¸°ì„ì› ë³µê·€ ì‹œê¸‰ ì‚¬ë²•...</td>\n",
       "      <td>2063</td>\n",
       "      <td>2037</td>\n",
       "      <td>0</td>\n",
       "      <td>. \"ë°˜ë„ì²´Â·ë””ìŠ¤í”Œë ˆì´Â·AIÂ·ë°”ì´ì˜¤ì— íˆ¬ì ì—­ëŸ‰ ì§‘ì¤‘í•´ì•¼\" [ì‚¼ì„± 'ì‹ ê²½ì˜... ì „...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1862</td>\n",
       "      <td>1429</td>\n",
       "      <td>1568</td>\n",
       "      <td>1568</td>\n",
       "      <td>ì‚¼ì„±å®¶, ìƒì†ì„¸ ë‚´ë ¤ê³  4ì¡° ëŒ€ì¶œ... 2ë…„ê°„ 6ì¡° ëƒˆì§€ë§Œ ì•„ì§ 6ì¡° ...</td>\n",
       "      <td>2023.06.06 19:20</td>\n",
       "      <td>ëŒ€ì¶œì´ìë§Œ ï¦ 2000ì–µ ë„˜ì–´ ì „ìÂ·SDSÂ·ìƒëª… ì¼ë¶€ ì£¼ì‹ ë§¤ê°ì´ê±´í¬ ì‚¼ì„± ì„ ëŒ€íšŒì¥...</td>\n",
       "      <td>ëŒ€ì¶œì´ìë§Œ ï¦ 2000ì–µ ë„˜ì–´ ì „ìÂ·SDSÂ·ìƒëª… ì¼ë¶€ ì£¼ì‹ ë§¤ê°ì´ê±´í¬ ì‚¼ì„± ì„ ëŒ€íšŒì¥...</td>\n",
       "      <td>1575</td>\n",
       "      <td>1571</td>\n",
       "      <td>0</td>\n",
       "      <td>. ì‚¼ì„±å®¶, ìƒì†ì„¸ ë‚´ë ¤ê³  4ì¡° ëŒ€ì¶œ... 2ë…„ê°„ 6ì¡° ëƒˆì§€ë§Œ ì•„ì§ 6ì¡° ... ëŒ€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>1863</td>\n",
       "      <td>1430</td>\n",
       "      <td>1569</td>\n",
       "      <td>1569</td>\n",
       "      <td>ì´ê±´í¬ê°€ ë§Œë“  'í’ˆì§ˆì˜ ì‚¼ì„±'â€¦JY 'ì´ˆì¼ë¥˜ ì‚¼ì„±'ìœ¼ë¡œ ê³„ìŠ¹í•œë‹¤</td>\n",
       "      <td>2023.06.06 18:30</td>\n",
       "      <td>íšŒì¥ 2ë…„ì°¨ ë§ì€ ì´ì¬ìš© 'ì œ2ì˜ æ–°ê²½ì˜' ë‚´ë†“ëŠ”ë‹¤  ï§¡, êµ­ë‚´ 1ìœ„ ìë§Œì— ë¶ˆëŸ‰ ...</td>\n",
       "      <td>íšŒì¥ 2ë…„ì°¨ ë§ì€ ì´ì¬ìš© 'ì œ2ì˜ æ–°ê²½ì˜' ë‚´ë†“ëŠ”ë‹¤  ï§¡, êµ­ë‚´ 1ìœ„ ìë§Œì— ë¶ˆëŸ‰ ...</td>\n",
       "      <td>1738</td>\n",
       "      <td>1654</td>\n",
       "      <td>1</td>\n",
       "      <td>. ì´ê±´í¬ê°€ ë§Œë“  'í’ˆì§ˆì˜ ì‚¼ì„±'â€¦JY 'ì´ˆì¼ë¥˜ ì‚¼ì„±'ìœ¼ë¡œ ê³„ìŠ¹í•œë‹¤ íšŒì¥ 2ë…„ì°¨ ë§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>1864</td>\n",
       "      <td>1431</td>\n",
       "      <td>1570</td>\n",
       "      <td>1570</td>\n",
       "      <td>'2ë‚˜ë…¸' ë¨¼ì € ì¹˜ê³  ë‚˜ê°„ TSMC... ì‚¼ì„±Â·ì¸í…”ë„ ì´ˆë¯¸ì„¸ ê³µì • ì¶”ê²©</td>\n",
       "      <td>2023.06.06 18:28</td>\n",
       "      <td>ê¸€ë¡œë²Œ íŒŒìš´ë“œë¦¬(ë°˜ë„ì²´ ìœ„íƒìƒì‚°) 1ìœ„ ì—…ì²´ì¸ ëŒ€ë§Œ TSMCê°€ 2ë‚˜ë…¸ë¯¸í„°(1nm=1...</td>\n",
       "      <td>ê¸€ë¡œë²Œ íŒŒìš´ë“œë¦¬ 1ìœ„ ì—…ì²´ì¸ ëŒ€ë§Œ TSMCê°€ 2ë‚˜ë…¸ë¯¸í„° ê³µì • ê°œë°œì— ì°©ìˆ˜í•˜ë©´ì„œ ê²½ìŸ...</td>\n",
       "      <td>1486</td>\n",
       "      <td>1397</td>\n",
       "      <td>1</td>\n",
       "      <td>. '2ë‚˜ë…¸' ë¨¼ì € ì¹˜ê³  ë‚˜ê°„ TSMC... ì‚¼ì„±Â·ì¸í…”ë„ ì´ˆë¯¸ì„¸ ê³µì • ì¶”ê²© ê¸€ë¡œë²Œ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1865</td>\n",
       "      <td>1432</td>\n",
       "      <td>1571</td>\n",
       "      <td>1571</td>\n",
       "      <td>â€œ1ë§ŒëŒ€ ëª¨ë‘ ì™„íŒì…ë‹ˆë‹¤â€ ë§í•œ ì¤„ ì•Œì•˜ëŠ”ë°, ì´ëŸ°ì¼ì´â€¦ì‚¼ì„± â€˜ì´ˆë¹„ìƒâ€™</td>\n",
       "      <td>2023.06.06 16:52</td>\n",
       "      <td>ëª¨í† ë¡œë¼ í´ë”ë¸”í° â€˜ë ˆì´ì €40 ìš¸íŠ¸ë¼â€™ [ì‚¬ì§„, GSMì•„ë ˆë‚˜][í—¤ëŸ´ë“œê²½ì œ= ë°•ì˜í›ˆê¸°...</td>\n",
       "      <td>ëª¨í† ë¡œë¼ í´ë”ë¸”í° â€˜ë ˆì´ì €40 ìš¸íŠ¸ë¼â€™  â€œë§í•  ì¤„ ì•˜ì•˜ëŠ”ë°'  ì¤‘êµ­ìœ¼ë¡œ ë„˜ì–´ê°„ ëª¨...</td>\n",
       "      <td>1481</td>\n",
       "      <td>1410</td>\n",
       "      <td>1</td>\n",
       "      <td>. â€œ1ë§ŒëŒ€ ëª¨ë‘ ì™„íŒì…ë‹ˆë‹¤â€ ë§í•œ ì¤„ ì•Œì•˜ëŠ”ë°, ì´ëŸ°ì¼ì´â€¦ì‚¼ì„± â€˜ì´ˆë¹„ìƒâ€™ ëª¨í† ë¡œë¼...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                0             0             0           0   \n",
       "1                2             2             2           2   \n",
       "2                3             3             3           3   \n",
       "3                4             4             4           4   \n",
       "4                5             5             5           5   \n",
       "...            ...           ...           ...         ...   \n",
       "1816          1861          1428          1567        1567   \n",
       "1817          1862          1429          1568        1568   \n",
       "1818          1863          1430          1569        1569   \n",
       "1819          1864          1431          1570        1570   \n",
       "1820          1865          1432          1571        1571   \n",
       "\n",
       "                                           title              date  \\\n",
       "0     ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ...  2023.07.10 15:29   \n",
       "1               â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—°  2023.07.10 15:07   \n",
       "2               SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰  2023.07.10 15:05   \n",
       "3           â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ  2023.07.10 14:58   \n",
       "4                ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤  2023.07.10 14:48   \n",
       "...                                          ...               ...   \n",
       "1816  \"ë°˜ë„ì²´Â·ë””ìŠ¤í”Œë ˆì´Â·AIÂ·ë°”ì´ì˜¤ì— íˆ¬ì ì—­ëŸ‰ ì§‘ì¤‘í•´ì•¼\" [ì‚¼ì„± 'ì‹ ê²½ì˜...  2023.06.06 19:20   \n",
       "1817  ì‚¼ì„±å®¶, ìƒì†ì„¸ ë‚´ë ¤ê³  4ì¡° ëŒ€ì¶œ... 2ë…„ê°„ 6ì¡° ëƒˆì§€ë§Œ ì•„ì§ 6ì¡° ...  2023.06.06 19:20   \n",
       "1818         ì´ê±´í¬ê°€ ë§Œë“  'í’ˆì§ˆì˜ ì‚¼ì„±'â€¦JY 'ì´ˆì¼ë¥˜ ì‚¼ì„±'ìœ¼ë¡œ ê³„ìŠ¹í•œë‹¤  2023.06.06 18:30   \n",
       "1819     '2ë‚˜ë…¸' ë¨¼ì € ì¹˜ê³  ë‚˜ê°„ TSMC... ì‚¼ì„±Â·ì¸í…”ë„ ì´ˆë¯¸ì„¸ ê³µì • ì¶”ê²©  2023.06.06 18:28   \n",
       "1820     â€œ1ë§ŒëŒ€ ëª¨ë‘ ì™„íŒì…ë‹ˆë‹¤â€ ë§í•œ ì¤„ ì•Œì•˜ëŠ”ë°, ì´ëŸ°ì¼ì´â€¦ì‚¼ì„± â€˜ì´ˆë¹„ìƒâ€™  2023.06.06 16:52   \n",
       "\n",
       "                                                content  \\\n",
       "0     ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...   \n",
       "1     ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...   \n",
       "2     í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥[ì„œìš¸=ë‰´ì‹œìŠ¤] SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥. (...   \n",
       "3     ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...   \n",
       "4     29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...   \n",
       "...                                                 ...   \n",
       "1816  ì „ë¬¸ê°€ê°€ ë³´ëŠ” ë‰´ì‚¼ì„± ì „ëµ ë¹„ë©”ëª¨ë¦¬ì— ìŠ¹ë¶€ìˆ˜ ë˜ì ¸ì•¼ ì´ì¬ìš© ë“±ê¸°ì„ì› ë³µê·€ ì‹œê¸‰ ì‚¬ë²•...   \n",
       "1817  ëŒ€ì¶œì´ìë§Œ ï¦ 2000ì–µ ë„˜ì–´ ì „ìÂ·SDSÂ·ìƒëª… ì¼ë¶€ ì£¼ì‹ ë§¤ê°ì´ê±´í¬ ì‚¼ì„± ì„ ëŒ€íšŒì¥...   \n",
       "1818  íšŒì¥ 2ë…„ì°¨ ë§ì€ ì´ì¬ìš© 'ì œ2ì˜ æ–°ê²½ì˜' ë‚´ë†“ëŠ”ë‹¤  ï§¡, êµ­ë‚´ 1ìœ„ ìë§Œì— ë¶ˆëŸ‰ ...   \n",
       "1819  ê¸€ë¡œë²Œ íŒŒìš´ë“œë¦¬(ë°˜ë„ì²´ ìœ„íƒìƒì‚°) 1ìœ„ ì—…ì²´ì¸ ëŒ€ë§Œ TSMCê°€ 2ë‚˜ë…¸ë¯¸í„°(1nm=1...   \n",
       "1820  ëª¨í† ë¡œë¼ í´ë”ë¸”í° â€˜ë ˆì´ì €40 ìš¸íŠ¸ë¼â€™ [ì‚¬ì§„, GSMì•„ë ˆë‚˜][í—¤ëŸ´ë“œê²½ì œ= ë°•ì˜í›ˆê¸°...   \n",
       "\n",
       "                                         content_corpus  content_len  \\\n",
       "0     ì±—GPT ì‹œëŒ€ í™”ë‘ë¡œ ë– ì˜¤ë¥¸ ì „ë ¥íš¨ìœ¨ì„± ë¬¸ì œ â€ì „ë ¥ ë¨¹ëŠ” í•˜ë§ˆ, Dë¨ ì „ë ¥íš¨ìœ¨ì„± ê°œ...         1813   \n",
       "1     ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ê°ì— ì‚¼ì„±ë‹·ì»´ ë‚´ e-ì‹í’ˆê´€ì—ì„œ  í• ì¸í˜œíƒ ì£¼ë©° â€˜ë½ì¸â€™ ê¸°ëŒ€ ...         1749   \n",
       "2     í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µëµâ€¦B2B ì‚¬ì—… í™•ì¥ SGCì†”ë£¨ì…˜ ë…¼ì‚° ê³µì¥.  .   ìƒí™œìœ ë¦¬...          547   \n",
       "3     ë¶ë¯¸Â·ìœ ëŸ½ ë“± ì˜ˆì•½ íŒë§¤ 3000ëŒ€ ëŒíŒŒ 10ì¼ ì˜¤í›„ 6ì‹œ ì‚¼ì„±ë‹·ì»´ â€˜í˜ì´ì»¤â€™ ì¶œì—°...         1096   \n",
       "4     29ë…„ê°„ 3ë§Œ6558í¸ ë…¼ë¬¸ ì ‘ìˆ˜â€¦ìˆ˜ìƒì 5312ëª… 9ì›”1ì¼ë¶€í„° ì˜¬í•´ ëŒ€ìƒ ì ‘ìˆ˜â€¦ìƒ...         1759   \n",
       "...                                                 ...          ...   \n",
       "1816  ì „ë¬¸ê°€ê°€ ë³´ëŠ” ë‰´ì‚¼ì„± ì „ëµ ë¹„ë©”ëª¨ë¦¬ì— ìŠ¹ë¶€ìˆ˜ ë˜ì ¸ì•¼ ì´ì¬ìš© ë“±ê¸°ì„ì› ë³µê·€ ì‹œê¸‰ ì‚¬ë²•...         2063   \n",
       "1817  ëŒ€ì¶œì´ìë§Œ ï¦ 2000ì–µ ë„˜ì–´ ì „ìÂ·SDSÂ·ìƒëª… ì¼ë¶€ ì£¼ì‹ ë§¤ê°ì´ê±´í¬ ì‚¼ì„± ì„ ëŒ€íšŒì¥...         1575   \n",
       "1818  íšŒì¥ 2ë…„ì°¨ ë§ì€ ì´ì¬ìš© 'ì œ2ì˜ æ–°ê²½ì˜' ë‚´ë†“ëŠ”ë‹¤  ï§¡, êµ­ë‚´ 1ìœ„ ìë§Œì— ë¶ˆëŸ‰ ...         1738   \n",
       "1819  ê¸€ë¡œë²Œ íŒŒìš´ë“œë¦¬ 1ìœ„ ì—…ì²´ì¸ ëŒ€ë§Œ TSMCê°€ 2ë‚˜ë…¸ë¯¸í„° ê³µì • ê°œë°œì— ì°©ìˆ˜í•˜ë©´ì„œ ê²½ìŸ...         1486   \n",
       "1820  ëª¨í† ë¡œë¼ í´ë”ë¸”í° â€˜ë ˆì´ì €40 ìš¸íŠ¸ë¼â€™  â€œë§í•  ì¤„ ì•˜ì•˜ëŠ”ë°'  ì¤‘êµ­ìœ¼ë¡œ ë„˜ì–´ê°„ ëª¨...         1481   \n",
       "\n",
       "      content_corpus_len  labels  \\\n",
       "0                   1651       1   \n",
       "1                   1698       0   \n",
       "2                    476       1   \n",
       "3                   1029       1   \n",
       "4                   1659       1   \n",
       "...                  ...     ...   \n",
       "1816                2037       0   \n",
       "1817                1571       0   \n",
       "1818                1654       1   \n",
       "1819                1397       1   \n",
       "1820                1410       1   \n",
       "\n",
       "                                             new_column  \n",
       "0     . ë°ì´í„°ì„¼í„° ì „ë ¥ 40% ì°¨ì§€í•˜ëŠ” Dë¨â€¦ ì‚¼ì„±Â·SKí•˜ì´ë‹‰ìŠ¤, â€˜ì „ì„±ë¹„â€™ ... ì±—...  \n",
       "1     . â€œì‚¼ì„±ì „ìê°€ ì‹í’ˆë„ íŒ”ì•˜ì–´?â€â€¦ì‹ ê·œ ê°€ì… ì¼ë‹¨ ì¢…ë£Œí•œ ì‚¬ì—° ì‚¼ì„± ê°€ì „ì œí’ˆ êµ¬ë§¤ê³ ...  \n",
       "2     . SGCì†”ë£¨ì…˜ 'ë„ì–´ê¸€ë¼ìŠ¤'â€¦ì‚¼ì„±Â·LG ì„¸íƒê¸°Â·ê±´ì¡°ê¸°ì— ê³µê¸‰ í•´ì™¸ ê°€ì „ ë¸Œëœë“œ ê³µ...  \n",
       "3     . â€˜í˜ì´ì»¤â€™ ë‚´ì„¸ìš´ ì‚¼ì„± OLED ê²Œì´ë° ëª¨ë‹ˆí„° ê¸€ë¡œë²Œ 3ì²œëŒ€ ëŒíŒŒ ë¶ë¯¸Â·ìœ ëŸ½ ë“±...  \n",
       "4     . ë„¤ì´ì²˜ ê²Œì¬ ë“± ì„±ê³¼â€¦ì‚¼ì„±íœ´ë¨¼í…Œí¬ë…¼ë¬¸ëŒ€ìƒ, 30ë…„ ë§ì•˜ë‹¤ 29ë…„ê°„ 3ë§Œ6558í¸...  \n",
       "...                                                 ...  \n",
       "1816  . \"ë°˜ë„ì²´Â·ë””ìŠ¤í”Œë ˆì´Â·AIÂ·ë°”ì´ì˜¤ì— íˆ¬ì ì—­ëŸ‰ ì§‘ì¤‘í•´ì•¼\" [ì‚¼ì„± 'ì‹ ê²½ì˜... ì „...  \n",
       "1817  . ì‚¼ì„±å®¶, ìƒì†ì„¸ ë‚´ë ¤ê³  4ì¡° ëŒ€ì¶œ... 2ë…„ê°„ 6ì¡° ëƒˆì§€ë§Œ ì•„ì§ 6ì¡° ... ëŒ€...  \n",
       "1818  . ì´ê±´í¬ê°€ ë§Œë“  'í’ˆì§ˆì˜ ì‚¼ì„±'â€¦JY 'ì´ˆì¼ë¥˜ ì‚¼ì„±'ìœ¼ë¡œ ê³„ìŠ¹í•œë‹¤ íšŒì¥ 2ë…„ì°¨ ë§...  \n",
       "1819  . '2ë‚˜ë…¸' ë¨¼ì € ì¹˜ê³  ë‚˜ê°„ TSMC... ì‚¼ì„±Â·ì¸í…”ë„ ì´ˆë¯¸ì„¸ ê³µì • ì¶”ê²© ê¸€ë¡œë²Œ ...  \n",
       "1820  . â€œ1ë§ŒëŒ€ ëª¨ë‘ ì™„íŒì…ë‹ˆë‹¤â€ ë§í•œ ì¤„ ì•Œì•˜ëŠ”ë°, ì´ëŸ°ì¼ì´â€¦ì‚¼ì„± â€˜ì´ˆë¹„ìƒâ€™ ëª¨í† ë¡œë¼...  \n",
       "\n",
       "[1821 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = train_test_split(data['content_corpus'], data['labels'],\n",
    "\n",
    "# train_dataset, test_dataset = train_test_split(data['new_column'], data['labels'],\n",
    "#                             test_size=0.2, shuffle=True, stratify=data['labels'], # labelì— ë¹„ìœ¨ì„ ë§ì¶°ì„œ ë¶„ë¦¬\n",
    "#                             random_state=SEED)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(data,\n",
    "                            test_size=0.3, shuffle=True, stratify=data['labels'], # labelì— ë¹„ìœ¨ì„ ë§ì¶°ì„œ ë¶„ë¦¬\n",
    "                            random_state=SEED)\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_dataset,\n",
    "                            test_size=0.2, shuffle=True, stratify=train_dataset['labels'], # labelì— ë¹„ìœ¨ì„ ë§ì¶°ì„œ ë¶„ë¦¬\n",
    "                            random_state=SEED)\n",
    "\n",
    "corpus_train, label_train = train_dataset[\"new_column\"], train_dataset[\"labels\"]\n",
    "corpus_val, label_val = val_dataset[\"new_column\"], val_dataset[\"labels\"]\n",
    "corpus_test, label_test = test_dataset[\"new_column\"], test_dataset[\"labels\"]\n",
    "\n",
    "# sentence_train, sentence_val, label_train, label_val = dataset\n",
    "\n",
    "\n",
    "max_length=500\n",
    "stride=10\n",
    "## TODO ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì°¨í›„ ìˆ˜ì •\n",
    "train_encoding = tokenizer(corpus_train.tolist(), ## pandas.Series -> list\n",
    "                            return_tensors='pt',\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            ##\n",
    "                            max_length=max_length,\n",
    "                            stride=stride,\n",
    "                            return_overflowing_tokens=True,\n",
    "                            return_offsets_mapping=False\n",
    "                            )\n",
    "\n",
    "val_encoding = tokenizer(corpus_val.tolist(),\n",
    "                        return_tensors='pt',\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        ##\n",
    "                        max_length=max_length,\n",
    "                        stride=stride,\n",
    "                        return_overflowing_tokens=True,\n",
    "                        return_offsets_mapping=False\n",
    "                        )\n",
    "\n",
    "train_set = SentimentalDataset(train_encoding, label_train.reset_index(drop=True))\n",
    "val_set = SentimentalDataset(val_encoding, label_val.reset_index(drop=True))\n",
    "test_set = SentimentalDataset(val_encoding, label_test.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = train_test_split(data['content_corpus'], data['labels'],\n",
    "\n",
    "dataset = train_test_split(data['new_column'], data['labels'],\n",
    "                            test_size=0.2, shuffle=True, stratify=data['labels'], # labelì— ë¹„ìœ¨ì„ ë§ì¶°ì„œ ë¶„ë¦¬\n",
    "                            random_state=SEED)\n",
    "\n",
    "\n",
    "sentence_train, sentence_val, label_train, label_val = dataset\n",
    "\n",
    "\n",
    "max_length=500\n",
    "stride=10\n",
    "## TODO ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì°¨í›„ ìˆ˜ì •\n",
    "train_encoding = tokenizer(sentence_train.tolist(), ## pandas.Series -> list\n",
    "                            return_tensors='pt',\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            ##\n",
    "                            max_length=max_length,\n",
    "                            stride=stride,\n",
    "                            return_overflowing_tokens=True,\n",
    "                            return_offsets_mapping=False\n",
    "                            )\n",
    "\n",
    "val_encoding = tokenizer(sentence_val.tolist(),\n",
    "                        return_tensors='pt',\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        ##\n",
    "                        max_length=max_length,\n",
    "                        stride=stride,\n",
    "                        return_overflowing_tokens=True,\n",
    "                        return_offsets_mapping=False\n",
    "                        )\n",
    "\n",
    "train_set = SentimentalDataset(train_encoding, label_train.reset_index(drop=True))\n",
    "val_set = SentimentalDataset(val_encoding, label_val.reset_index(drop=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ (huggingface)\n",
    "#### hyperparameter\n",
    "- max_length\n",
    "- stride\n",
    "- num_train_epoch\n",
    "- learning_rate\n",
    "- per_device_train_batch_size\n",
    "- per_device_eval_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = 200\n",
    "num_train_epochs = 2\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "learning_rate = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [730/730 02:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.282900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=730, training_loss=0.37612260269792114, metrics={'train_runtime': 187.8492, 'train_samples_per_second': 15.544, 'train_steps_per_second': 3.886, 'total_flos': 2657460528240000.0, 'train_loss': 0.37612260269792114, 'epoch': 2.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run = wandb.init(project=\"final_sentimental\", entity=\"nlp-10\")\n",
    "\n",
    "# run.name = f\"model: {MODEL_NAME} / batch_size: {per_device_train_batch_size} / lr: {learning_rate}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './outputs',\n",
    "    logging_steps = logging_steps,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    per_device_train_batch_size = per_device_train_batch_size,\n",
    "    per_device_eval_batch_size = per_device_eval_batch_size,\n",
    "    learning_rate = learning_rate,\n",
    "    evaluation_strategy=\"logging_steps\"\n",
    "    fp16=True,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print('---train start---')\n",
    "trainer.train()\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---val evaulate start---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val1_loss': 0.3280849754810333,\n",
       " 'val1_accuracy': 0.9372549019607843,\n",
       " 'val1_f1': 0.9372549019607843}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---val evaulate start---')\n",
    "# wandb.init()\n",
    "trainer.evaluate(eval_dataset=val_set, metric_key_prefix='val1')\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ(wandb_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {'name': f\"{MODEL_NAME}_1\",  # name : sweep_name\n",
    "                    'method': 'grid',  # 'grid', 'uniform', 'bayesian'\n",
    "                    'parameters': {\n",
    "                        'lr': {  # parameter  ì‘ì„±ë°©ì‹ ì—¬ëŸ¬ê°œ ìˆìœ¼ë‹ˆê¹Œ, ë…¸ì…˜ ë¬¸ì„œ ì°¸ê³ \n",
    "                            'values': [4e-6, 5e-6, 6e-6]\n",
    "                        },\n",
    "                        'warmup_step': {\n",
    "                            \"values\": [200]\n",
    "                        },\n",
    "                        'logging_steps': {\n",
    "                            \"values\": [200]\n",
    "                        },\n",
    "                        \"batch_size\": {\n",
    "                            \"values\": [8]\n",
    "                        },\n",
    "                        \"max_epoch\": {\n",
    "                            \"values\": [2]\n",
    "                        },\n",
    "                    },\n",
    "                    # goal : maximize, minimize\n",
    "                    'metric': {'name': 'val1_accuracy', 'goal': 'maximize'}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mode\n",
      "Create sweep with ID: tdlke131\n",
      "Sweep URL: https://wandb.ai/nlp-10/final_sentimental/sweeps/tdlke131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# print(\"Training with sweep mode\")\n",
    "\n",
    "# sweep_id = wandb.sweep(json.load(open(\"/opt/ml/level3_nlp_finalproject-nlp-04/sentence-sentimental/sweep.json\", \"r\"), object_hook=_decode), project=\"final_sentimental\", entity=\"nlp-10\")\n",
    "# wandb.agent(sweep_id, trainWithSweep, count=int(5))\n",
    "# wandb.finish()\n",
    "from train import sweep_train\n",
    "\n",
    "print(\"Train mode\")\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"final_sentimental\", entity=\"nlp-10\")\n",
    "wandb.agent(sweep_id, sweep_train, count=3)\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [303/303 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/level3_nlp_finalproject-nlp-04/sentence-sentimental/metrics/metrics.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  acc = load_metric('accuracy').compute(predictions=preds, references=labels)['accuracy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val1_loss': 0.5156943798065186,\n",
       " 'val1_accuracy': 0.8489475856376393,\n",
       " 'val1_f1': 0.8489475856376393,\n",
       " 'val1_runtime': 12.6519,\n",
       " 'val1_samples_per_second': 191.513,\n",
       " 'val1_steps_per_second': 23.949,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---inference start---\n",
      "tensor([2.0495e-01, 9.4348e-05, 7.9496e-01])\n"
     ]
    }
   ],
   "source": [
    "print('---inference start---')\n",
    "my_text = 'ì‚¼ì„±ì „ì, ì˜¬í•´ë¶€í„° ë‹¤ìš´í„´ ëë‚˜ê³  ë§¤ì¶œ ìƒìŠ¹ ì‹œì‘í•  ë“¯'*10\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "with torch.no_grad() :\n",
    "    temp = tokenizer(\n",
    "        my_text,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        ##\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=False\n",
    "        )\n",
    "    temp = {\n",
    "        'input_ids':temp['input_ids'],\n",
    "        'token_type_ids':temp['token_type_ids'],\n",
    "        'attention_mask':temp['attention_mask'],\n",
    "    }\n",
    "    predicted_label = model(**temp)\n",
    "    print(torch.nn.Softmax(dim=-1)(predicted_label.logits).mean(dim=0))\n",
    "    # tensor([[0.0108, 0.1264, 0.8628]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "981f108a204f421f158e0977940335d851edffa6dd3586828a3e1aec045160e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

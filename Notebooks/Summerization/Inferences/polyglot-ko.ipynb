{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a261904d-247d-4afc-9770-752f5efdbd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/peft/blob/main/examples/causal_language_modeling/peft_prompt_tuning_clm.ipynb\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, LlamaTokenizer\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dde56cc-c4d4-4177-bfd0-565aea0426c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bdf22c469d45388c7edc337a44fbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apater_id = \"./polyglot-ko_5.8b_news_3ep\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(apater_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, apater_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c340cc-386a-4ce7-be01-a93181532d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(contents):\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            f\"\"\"### 질문: 아래의 문서를 요약해줘. \n",
    "\n",
    "###맥락: {contents}\n",
    "\n",
    "### 답변:\"\"\",\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ),\n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "        no_repeat_ngram_size=8,\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe35d61-6ee1-4dcf-9ef4-b7b00ab0e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 질문: 아래의 문서를 요약해줘. \n",
      "\n",
      "###맥락: 챗GPT 시대 화두로 떠오른 전력효율성 문제 ”전력 먹는 하마, D램 전력효율성 개선이 최대 과제” 삼성·SK하이닉스, 차세대 HBM도 전성비 확보 고심삼성전자의 12나노급 D램./삼성전자 제공삼성전자, SK하이닉스 등 메모리 반도체 기업들이 주요 연구소, 학술기관, 대학교 등과 함께 서버용 D램의 소비전력을 낮추기 위한 솔루션 개발을 진행 중이다. 차세대 제품군에서는 고대역폭메모리(HBM) 제품에 전성비(소비전력 대비 성능)를 높이기 위한 기술 도입을 검토하고 있으며, 기존 DDR5 제품을 바탕으로 한 서버용 솔루션에서도 전성비가 최대 화두로 떠올랐다.  10일 반도체업계에 따르면 현재 최선단 기술을 바탕으로 설계되고 있는 챗GPT용 인공지능(AI) 모델 구축 과정에서 D램의 소비전력이 과도하게 높다는 문제 인식이 커지고 있다. 업계에서 가장 각광받고 있는 엔비디아 A100 기반 데이터센터 플랫폼 역시 D램 소비전력이 전체 전력소비량의 약 40%를 차지할 정도로 막대한 비중을 차지하는 것으로 알려졌다.  삼성전자의 경우 용량 확장성이 강점인 컴퓨트 익스프레스 링크(Compute eXpress Link·CXL) 메모리 기술을 바탕으로 소비전력 분산에 집중한 아키텍처 설계에 공을 들이고 있다. 지난해 말에는 12나노미터(nm)급 16기가바이트(GB) DDR5 D램을 개발하며 이전 세대 제품보다 소비전력을 23% 개선하는데 성공했다.  삼성전자에 정통한 관계자는 “미세공정 수율뿐 아니라 D램 아키텍처상에서 전력소모량을 더 줄일 수 있는 소프트웨어적 호환성도 중요한 이슈로 부각되고 있다”며 “D램 설계과정에서부터 전력 누수를 줄이는 방법을 고안하기 위해 서울대를 비롯한 각종 연구소와 산학협력 과제들을 다수 진행하고 있다”라고 말했다.  SK하이닉스의 경우 모바일 D램 제품에 처음으로 HKMG(High-K Metal Gate) 공정을 적용한 LPDDR5X(Low Power Double Data Rate 5X) 개발에 성공했다. HKMG 공정은 유전율(K)이 높은 물질을 D램 트랜지스터 내부의 절연막에 사용, 누설 전류를 막고 정전용량을 개선한 차세대 공정이다. 속도를 빠르게 하면서도 소모 전력을 줄일 수 있는 것이 특징이다.  LPDDR5X 신제품은 초고속을 구현하는 동시에 국제반도체표준협의기구(JEDEC)가 정한 초저전압 범위인 1.01∼1.12V(볼트)에서 작동한다. 그 결과 기존 제품 대비 소비전력이 25% 줄어 현재 시장에 출시된 모바일 D램 중 전력사용 효율성이 가장 높다고 SK하이닉스는 설명했다.  챗GPT 시대 필수재로 꼽히는 HBM도 적층수가 높아질수록 전력 소모가 늘어나는 문제를 해결하기 위해 두 회사 모두 골머리를 앓고 있는 상황이다. 내년에 출시될 HBM3의 후속 제품은 고객사 측에서 전력 소모 감축을 조건으로 제시하고 있고, 이에 두 회사는 대역폭이 높아질수록 전력 소모량이 늘어나는 문제를 잡기 위해 다양한 신기술을 테스트하고 있다.  기업뿐 아니라 대학 등 연구기관에서도 전성비 확보를 위한 새로운 메모리 기술 연구에 박차를 가하고 있다. 서울대 연구진은 최근 D램 변환 계층(DTL·Dram Translation Layer)이라는 새로운 기술을 발표하며 D램을 별개의 레이어(층)로 나눠 전력 효율성을 높이는 시도를 논문으로 발표했다. 해당 기술을 사용할 경우 이론적으로 D램 전력을 31.6%가량 절약할 수 있다.  반도체업계 관계자는 “수년 전부터 본격화된 ESG(환경·사회·지배구조) 흐름은 이제 거스를 수 없는 대세가 됐고 삼성전자, SK하이닉스 등은 전력효율성에 초점을 맞추기 시작했다”며 “전성비 기술을 놓고 두 회사의 경쟁이 더욱 치열해질 것으로 본다”라고 설명했다.\n",
      "\n",
      "### 답변: 삼성전자·SK하이닉스 등 메모리 반도체 기업들이 주요 연구실, 학술기관, 대학교 등과 데이터센터용 D램의 소비전력을 줄이기 위한 솔루션 개발을 진행중으로 서버용 D램의 소비전력이 과도할 경우 전력소비량도 소비전력의 20%이상 차지해 최대 화두로 떠올랐다. \n",
      "\n",
      "\n",
      "SK하이닉스는 모바일 D램 제품에 처음으로 LPDDR5X를 개발했고, 서울대는 대역폭이 높아질수록 소비전력이 늘어나는 문제를 잡기위해 다양한 신기술을 테스트하고있다. 또 삼성전자는 대역폭이 높아질수록전력 소모량이 늘어나는 문제를잡기위해 다양한 신기술을테스트중이다.\n",
      "\n",
      "SK하이닉스는 모바일 D렘 제품에 처음으로 HKMG 공정을 적용한 LPDDR 5X를 개발했고 삼성전자는 대역폭이 높아져 전력 소모량이 늘어나는 문제 해결을 위한 다양한 신기술을 테스트하고 현재 최선단 기술을 바탕으로 한 설계되고 있는 챗GKPT용  AI 인공지능 인공지능 AI 인공지능 AI 인공지능 인공지능 AI 인공지능 AI 인공지능 AI 인공지능 AI 인공지능 반도체AI 반도체AI 반도체AI 반도체AI 반도체 AI 인공지능 AI 인공지능 AI 인공지능AI 인공지능 AI AI 인공지능 인공지능 AI 인공지능 AI 인공지능 반도체 AI 반도체 AI 반도체 AI 반도체 AI 반도체 CPU CPU CPU CPU CPUS CPU CPU CPU CPFX F D D D D 압류 압류 압류 압류 압류 압류 압류  압류 압류 압류 압류 압류 압류 압류 압류 AI 인공지능 AI 인공지능 AI AI 인공지능 AI AI AI AI AI 인공지능 AI 인공지능 AI 인공지능 AI AI 인공지능 D램 D램 D램 D램 D렘 D램 D램  D램 D램 D램 D그램 D램 D램 D램 DLM D L DDR5 D램 D램 CAP D램 D램 D램 DRM DDR5 D램 LD DDR5 D램 LDR DDR5 D램 LM DDR5 D램 LR DDR5 D램 LP DDR5 D램 LR MQ D램 LM DDR5 MQ D렘 LM D 겉  D램 LD DDR5  D램 D램 D램  반도체 D램 D램 D램 DDR5 D램 D램  D램  D램 D램  D램 LDRDDR5 D램 D램 LMR  D렘 D램 D렘 D렘 D렘 D렘 D램 D램 DDR D\n"
     ]
    }
   ],
   "source": [
    "gen('챗GPT 시대 화두로 떠오른 전력효율성 문제 ”전력 먹는 하마, D램 전력효율성 개선이 최대 과제” 삼성·SK하이닉스, 차세대 HBM도 전성비 확보 고심삼성전자의 12나노급 D램./삼성전자 제공삼성전자, SK하이닉스 등 메모리 반도체 기업들이 주요 연구소, 학술기관, 대학교 등과 함께 서버용 D램의 소비전력을 낮추기 위한 솔루션 개발을 진행 중이다. 차세대 제품군에서는 고대역폭메모리(HBM) 제품에 전성비(소비전력 대비 성능)를 높이기 위한 기술 도입을 검토하고 있으며, 기존 DDR5 제품을 바탕으로 한 서버용 솔루션에서도 전성비가 최대 화두로 떠올랐다.  10일 반도체업계에 따르면 현재 최선단 기술을 바탕으로 설계되고 있는 챗GPT용 인공지능(AI) 모델 구축 과정에서 D램의 소비전력이 과도하게 높다는 문제 인식이 커지고 있다. 업계에서 가장 각광받고 있는 엔비디아 A100 기반 데이터센터 플랫폼 역시 D램 소비전력이 전체 전력소비량의 약 40%를 차지할 정도로 막대한 비중을 차지하는 것으로 알려졌다.  삼성전자의 경우 용량 확장성이 강점인 컴퓨트 익스프레스 링크(Compute eXpress Link·CXL) 메모리 기술을 바탕으로 소비전력 분산에 집중한 아키텍처 설계에 공을 들이고 있다. 지난해 말에는 12나노미터(nm)급 16기가바이트(GB) DDR5 D램을 개발하며 이전 세대 제품보다 소비전력을 23% 개선하는데 성공했다.  삼성전자에 정통한 관계자는 “미세공정 수율뿐 아니라 D램 아키텍처상에서 전력소모량을 더 줄일 수 있는 소프트웨어적 호환성도 중요한 이슈로 부각되고 있다”며 “D램 설계과정에서부터 전력 누수를 줄이는 방법을 고안하기 위해 서울대를 비롯한 각종 연구소와 산학협력 과제들을 다수 진행하고 있다”라고 말했다.  SK하이닉스의 경우 모바일 D램 제품에 처음으로 HKMG(High-K Metal Gate) 공정을 적용한 LPDDR5X(Low Power Double Data Rate 5X) 개발에 성공했다. HKMG 공정은 유전율(K)이 높은 물질을 D램 트랜지스터 내부의 절연막에 사용, 누설 전류를 막고 정전용량을 개선한 차세대 공정이다. 속도를 빠르게 하면서도 소모 전력을 줄일 수 있는 것이 특징이다.  LPDDR5X 신제품은 초고속을 구현하는 동시에 국제반도체표준협의기구(JEDEC)가 정한 초저전압 범위인 1.01∼1.12V(볼트)에서 작동한다. 그 결과 기존 제품 대비 소비전력이 25% 줄어 현재 시장에 출시된 모바일 D램 중 전력사용 효율성이 가장 높다고 SK하이닉스는 설명했다.  챗GPT 시대 필수재로 꼽히는 HBM도 적층수가 높아질수록 전력 소모가 늘어나는 문제를 해결하기 위해 두 회사 모두 골머리를 앓고 있는 상황이다. 내년에 출시될 HBM3의 후속 제품은 고객사 측에서 전력 소모 감축을 조건으로 제시하고 있고, 이에 두 회사는 대역폭이 높아질수록 전력 소모량이 늘어나는 문제를 잡기 위해 다양한 신기술을 테스트하고 있다.  기업뿐 아니라 대학 등 연구기관에서도 전성비 확보를 위한 새로운 메모리 기술 연구에 박차를 가하고 있다. 서울대 연구진은 최근 D램 변환 계층(DTL·Dram Translation Layer)이라는 새로운 기술을 발표하며 D램을 별개의 레이어(층)로 나눠 전력 효율성을 높이는 시도를 논문으로 발표했다. 해당 기술을 사용할 경우 이론적으로 D램 전력을 31.6%가량 절약할 수 있다.  반도체업계 관계자는 “수년 전부터 본격화된 ESG(환경·사회·지배구조) 흐름은 이제 거스를 수 없는 대세가 됐고 삼성전자, SK하이닉스 등은 전력효율성에 초점을 맞추기 시작했다”며 “전성비 기술을 놓고 두 회사의 경쟁이 더욱 치열해질 것으로 본다”라고 설명했다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eb54e-95fe-4fa8-a2cc-cdb4034c84c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
